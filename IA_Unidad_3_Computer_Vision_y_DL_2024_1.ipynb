{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-jFKoVjtpG0"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAc5bE406eF3"
      },
      "source": [
        "# Inteligencia artificial 2024-1\n",
        "## UNIDAD 3 - Introducción a Deep Learning\n",
        "\n",
        "#### Código fuente y contenido basado en:\n",
        "`MIT: Introduction to Deep Learning`\n",
        "\n",
        "Ejecutar en Google Colab\tVer código fuente en GitHub\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkq_pKOYt2zE"
      },
      "source": [
        "<table align=\"center\">\n",
        "\n",
        "<td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ulises1229/IA-2021-II/blob/main/code/IA_Unidad_4_Computer_Vision_y_DL.ipynb\">\n",
        "        <img src=\"https://i.ibb.co/2P3SLwK/colab.png\"  style=\"padding-bottom:5px;\" />Ejecutar en Google Colab</a></td>\n",
        "  <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/drive/1XqqtBBWcEHGFIPD4_6lDSEnfNRJVTmcI?usp=sharing\">\n",
        "        <img src=\"https://i.ibb.co/xfJbPmL/github.png\"  height=\"70px\" style=\"padding-bottom:5px;\"  />Ver código fuente en GitHub</a></td>\n",
        "\n",
        "\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1XpLftPi4A"
      },
      "source": [
        "\n",
        "#1. Clasificación de dígitos usando el set de datos MNIST\n",
        "\n",
        "En la primer parte crearemos y entrenaremos una red neuronal convolucional (CNN) para la clasificación de dígitos escritos a mano del famoso conjunto de datos [MNIST](http://yann.lecun.com/exdb/mnist/). El conjunto de datos MNIST consta de 60,000 imágenes de entrenamiento y 10,000 imágenes de prueba. Nuestras clases son los dígitos 0-9.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsGqx_ai_N8F"
      },
      "source": [
        "# Import Tensorflow 2.0\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "!pip install mitdeeplearning\n",
        "import mitdeeplearning as mdl\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Check that we are using a GPU, if not switch runtimes\n",
        "#   using Runtime > Change Runtime Type > GPU\n",
        "assert len(tf.config.list_physical_devices('GPU')) > 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKjrdUtX_N8J"
      },
      "source": [
        "## 1.1 Conjunto de datos MNIST\n",
        "\n",
        "Descarguemos y carguemos el conjunto de datos y mostremos algunas muestras aleatorias de él:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2dQsHI3_N8K"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "train_images = (np.expand_dims(train_images, axis=-1)/255.).astype(np.float32)\n",
        "train_labels = (train_labels).astype(np.int64)\n",
        "test_images = (np.expand_dims(test_images, axis=-1)/255.).astype(np.float32)\n",
        "test_labels = (test_labels).astype(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZtUqOqePsRD"
      },
      "source": [
        "Nuestro conjunto de formación se compone de imágenes en escala de grises de 28x28 de dígitos escritos a mano.\n",
        "\n",
        "Visualicemos cómo se ven algunas de estas imágenes y sus correspondientes etiquetas de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bDBsR2lP_N8O"
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "random_inds = np.random.choice(60000,36)\n",
        "for i in range(16):\n",
        "    plt.subplot(4,4,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    image_ind = random_inds[i]\n",
        "    plt.imshow(np.squeeze(train_images[image_ind]), cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[image_ind])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6hd3Nt1_N8q"
      },
      "source": [
        "## 1.2 Red neuronal para clasificación de dígitos escritos a mano\n",
        "\n",
        "Primero construiremos una red neuronal simple que consta de dos capas completamente conectadas y aplicaremos esto a la tarea de clasificación de dígitos. Nuestra red finalmente generará una distribución de probabilidad sobre las clases de 10 dígitos (0-9). Esta primera arquitectura que estaremos construyendo se muestra a continuación:\n",
        "\n",
        "![alt_text](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab2/img/mnist_2layers_arch.png \"CNN Architecture for MNIST Classification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rphS2rMIymyZ"
      },
      "source": [
        "### Arquitectura de red neuronal completamente conectada\n",
        "Para definir la arquitectura de esta primera red neuronal completamente conectada, una vez más usaremos la API de Keras y definiremos el modelo usando una red [`Sequential`](https://www.tensorflow.org/api_docs/python/tf/keras / modelos / secuencial). Observe cómo usamos primero una capa [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten), que aplana la entrada para que pueda introducirse en el modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMZsbjAkDKpU"
      },
      "source": [
        "def build_fc_model():\n",
        "  fc_model = tf.keras.Sequential([\n",
        "      # First define a Flatten layer\n",
        "      tf.keras.layers.Flatten(),\n",
        "\n",
        "      # '''TODO: Define the activation function for the first fully connected (Dense) layer.'''\n",
        "      tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      # tf.keras.layers.Dense(128, activation= '''TODO'''),\n",
        "        tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "      # '''TODO: Define the second Dense layer to output the classification probabilities'''\n",
        "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "      # [TODO Dense layer to output classification probabilities]\n",
        "\n",
        "  ])\n",
        "  return fc_model\n",
        "\n",
        "model = build_fc_model()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtGZpHVKz5Jt"
      },
      "source": [
        "A medida que avanzamos en la siguiente parte, es posible que se deseen realizar cambios en la arquitectura definida anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVN1_AeG_N9N"
      },
      "source": [
        "Demos un paso atrás y pensemos en la red que acabamos de crear. La primera capa de esta red, `tf.keras.layers.Flatten`, transforma el formato de las imágenes de una matriz 2d (28 x 28 píxeles) a una matriz 1d de 28 * 28 = 784 píxeles. Puede pensar en esta capa como desapilar filas de píxeles en la imagen y alinearlas. No hay parámetros aprendidos en esta capa; solo reformatea los datos.\n",
        "\n",
        "Una vez que los píxeles se aplanan, la red consta de una secuencia de dos capas `tf.keras.layers.Dense`. Estas son capas neuronales completamente conectadas. La primera capa \"Densa\" tiene 128 nodos (o neuronas). La segunda (y última) capa debe devolver una matriz de puntuaciones de probabilidad que sumen 1. Cada nodo contiene una puntuación que indica la probabilidad de que la imagen actual pertenezca a una de las clases de dígitos escritos a mano.\n",
        "\n",
        "¡Eso define nuestro modelo totalmente conectado!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "### Compilando el modelo\n",
        "\n",
        "Antes de entrenar el modelo, necesitamos definir algunas configuraciones más. Estas se agregan durante el paso del modelo [`compile`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#compile):\n",
        "\n",
        "* Función de pérdida *: define cómo medimos la precisión del modelo durante el entrenamiento. Como se cubrió en la conferencia, durante el entrenamiento queremos minimizar esta función, que \"dirigirá\" el modelo en la dirección correcta.\n",
        "> * Optimizador *: define cómo se actualiza el modelo en función de los datos que ve y su función de pérdida.\n",
        "> * Métricas *: aquí podemos definir las métricas utilizadas para monitorear los pasos de entrenamiento y prueba. En este ejemplo, veremos la * precisión *, la fracción de las imágenes que están clasificadas correctamente.\n",
        "\n",
        "Comenzaremos usando un optimizador de descenso de gradiente estocástico (SGD) inicializado con una tasa de aprendizaje de 0.1. Dado que estamos realizando una tarea de clasificación categórica, queremos usar la [pérdida de entropía cruzada](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_categorical_crossentropy).\n",
        "\n",
        "Se recomienda experimentar tanto con la elección del optimizador como con la tasa de aprendizaje y evaluar cómo estos afectan la precisión del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "source": [
        "'''TODO: Experiment with different optimizers and learning rates. How do these affect\n",
        "    the accuracy of the trained model? Which optimizers and/or learning rates yield\n",
        "    the best performance?'''\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-1),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "### Entrenando el modelo\n",
        "\n",
        "Ahora estamos listos para entrenar nuestro modelo, lo que implicará introducir los datos de entrenamiento (`train_images` y ` train_labels`) en el modelo, y luego pedirle que aprenda las asociaciones entre imágenes y etiquetas. También necesitaremos definir el tamaño de batch y el número de épocas, o iteraciones sobre el conjunto de datos MNIST, durante el entrenamiento.\n",
        "\n",
        "En la unidad pasada, vimos cómo podemos usar `GradientTape` para optimizar pérdidas y entrenar modelos con el método de descenso de gradiente estocástico. Después de definir la configuración del modelo en el paso `compile`, también podemos realizar el entrenamiento llamando al [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#fit) método que se instancia de la clase `Model`. Usaremos esto para entrenar nuestro modelo completamente conectado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFMbIqIvQ2X0"
      },
      "source": [
        "# Define the batch size and the number of epochs to use during training\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 5\n",
        "\n",
        "model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS, use_multiprocessing=True)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZVOhugCaXA"
      },
      "source": [
        "A medida que el modelo se entrena, se muestran las métricas de pérdida y precisión. Con cinco épocas y una tasa de aprendizaje de 0.01, este modelo completamente conectado debería lograr una precisión de aproximadamente 0.97 (o 97%) en los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "### Evaluar la precisión en el conjunto de datos de prueba\n",
        "\n",
        "Ahora que hemos entrenado el modelo, podemos pedirle que haga predicciones sobre un set de prueba que no haya visto antes. En este ejemplo, el tensor `test_images` comprende nuestro conjunto de datos de prueba. Para evaluar la precisión, podemos verificar si las predicciones del modelo coinciden con las etiquetas de la matriz `test_labels`.\n",
        "\n",
        "Utilice el método [`evaluate`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#evaluate) para evaluar el modelo en el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VflXLEeECaXC"
      },
      "source": [
        "'''TODO: Use the evaluate method to test the model!'''\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels) # TODO\n",
        "# test_loss, test_acc = # TODO\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWfgsmVXCaXG"
      },
      "source": [
        "Puede observar que la precisión en el conjunto de datos de prueba es un poco menor que la precisión en el conjunto de datos de entrenamiento. Esta brecha entre la precisión del entrenamiento y la precisión de la prueba es un ejemplo de * sobreajuste *, cuando un modelo de aprendizaje automático se desempeña peor en datos nuevos que en sus datos de entrenamiento.\n",
        "\n",
        "¿Cuál es la mayor precisión que puede lograr con este primer modelo completamente conectado? Dado que la tarea de clasificación de dígitos escritos a mano es bastante sencilla, es posible que se pregunte cómo podemos hacerlo mejor ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baIw9bDf8v6Z"
      },
      "source": [
        "## 1.3 Red neuronal convolucional (CNN) para clasificación de dígitos escritos a mano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J72Yt1o_fY7"
      },
      "source": [
        "Como vimos en la conferencia, las redes neuronales convolucionales (CNN) son particularmente adecuadas para una variedad de tareas en la visión por computadora y han logrado precisiones casi perfectas en el conjunto de datos MNIST. Ahora construiremos una CNN compuesta por dos capas convolucionales y capas agrupadas, seguidas de dos capas completamente conectadas, y finalmente generaremos una distribución de probabilidad sobre las clases de 10 dígitos (0-9). La CNN que estaremos construyendo se muestra a continuación:\n",
        "\n",
        "![alt_text](https://raw.githubusercontent.com/aamini/introtodeeplearning/master/lab2/img/convnet_fig.png \"Arquitectura CNN para clasificación MNIST\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEHqzbJJAEoR"
      },
      "source": [
        "### Definir el modelo de CNN\n",
        "\n",
        "Usaremos los mismos conjuntos de datos de entrenamiento y prueba que antes, y procederemos de manera similar a nuestra red completamente conectada para definir y entrenar nuestro nuevo modelo de CNN. Para hacer esto, exploraremos dos capas que no habíamos encontrado antes: puede usar [`keras.layers.Conv2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) para defina capas convolucionales y [`keras.layers.MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D) para definir las capas de agrupación. Utilice los parámetros que se muestran en la arquitectura de red anterior para definir estas capas y crear el modelo CNN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vec9qcJs-9W5"
      },
      "source": [
        "def build_cnn_model():\n",
        "    cnn_model = tf.keras.Sequential([\n",
        "\n",
        "        # TODO: Define the first convolutional layer\n",
        "        tf.keras.layers.Conv2D(filters=24, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        # tf.keras.layers.Conv2D('''TODO''')\n",
        "\n",
        "        # TODO: Define the first max pooling layer\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "        # tf.keras.layers.MaxPool2D('''TODO''')\n",
        "\n",
        "        # TODO: Define the second convolutional layer\n",
        "        tf.keras.layers.Conv2D(filters=36, kernel_size=(3,3), activation=tf.nn.relu),\n",
        "        # tf.keras.layers.Conv2D('''TODO''')\n",
        "\n",
        "        # TODO: Define the second max pooling layer\n",
        "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "        # tf.keras.layers.MaxPool2D('''TODO''')\n",
        "\n",
        "        tf.keras.layers.Flatten(),\n",
        "\n",
        "        tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "\n",
        "        # TODO: Define the last Dense layer to output the classification\n",
        "        # probabilities. Pay attention to the activation needed a probability\n",
        "        # output\n",
        "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "        # [TODO Dense layer to output classification probabilities]\n",
        "    ])\n",
        "\n",
        "    return cnn_model\n",
        "\n",
        "cnn_model = build_cnn_model()\n",
        "# Initialize the model by passing some data through\n",
        "plt.imshow(np.squeeze(train_images[0]), cmap=plt.cm.binary)\n",
        "\n",
        "print(cnn_model.predict(train_images[[0]]))\n",
        "# Print the summary of the layers in the model.\n",
        "print(cnn_model.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vheyanDkCg6a"
      },
      "source": [
        "'''TODO: Define the compile operation with your optimizer and learning rate of choice'''\n",
        "cnn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# cnn_model.compile(optimizer='''TODO''', loss='''TODO''', metrics=['accuracy']) # TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U19bpRddC7H_"
      },
      "source": [
        "Como fue el caso con el modelo completamente conectado, podemos entrenar nuestra CNN usando el método de \"ajuste\" a través de la API de Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdrGZVmWDK4p"
      },
      "source": [
        "'''TODO: Use model.fit to train the CNN model, with the same batch_size and number of epochs previously used.'''\n",
        "cnn_model.fit(train_images, train_labels, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
        "# cnn_model.fit('''TODO''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEszYWzgDeIc"
      },
      "source": [
        "Ahora que hemos entrenado el modelo, evaluémoslo en el conjunto de datos de prueba usando el método [`evaluar`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#evaluate):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDm4znZcDtNl"
      },
      "source": [
        "'''TODO: Use the evaluate method to test the model!'''\n",
        "test_loss, test_acc = cnn_model.evaluate(test_images, test_labels)\n",
        "# test_loss, test_acc = # TODO\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rvEgK82Glv9"
      },
      "source": [
        "¿Cuál es la precisión más alta que puede lograr con el modelo de CNN y cómo se compara la precisión del modelo de CNN con la precisión de la red simple completamente conectada? ¿Qué optimizadores y tasas de aprendizaje parecen ser óptimos para entrenar el modelo de CNN?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "### Haz predicciones con el modelo de CNN\n",
        "\n",
        "Con el modelo entrenado, podemos usarlo para hacer predicciones sobre algunas imágenes. La llamada a la función [`predict`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#predict) genera las predicciones de salida dado un conjunto de muestras de entrada.\n",
        "\n",
        "With the model trained, we can use it to make predictions about some images. The [`predict`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#predict) function call generates the output predictions given a set of input samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "source": [
        "#print(test_images)\n",
        "print(len(test_images))\n",
        "predictions = cnn_model.predict(test_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "Con esta llamada de función, el modelo ha predicho la etiqueta para cada imagen en el conjunto de prueba. Echemos un vistazo a la predicción de la primera imagen en el conjunto de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "Como puede ver, una predicción es una matriz de 10 números. Recuerde que el resultado de nuestro modelo es una distribución de probabilidad sobre las clases de 10 dígitos. Por lo tanto, estos números describen la \"confianza\" del modelo de que la imagen corresponde a cada uno de los 10 dígitos diferentes.\n",
        "\n",
        "Veamos el dígito que tiene la mayor confianza para la primera imagen en el conjunto de datos de prueba:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "source": [
        "'''TODO: identify the digit with the highest confidence prediction for the first\n",
        "    image in the test dataset. '''\n",
        "prediction = np.argmax(predictions[0])\n",
        "# prediction = # TODO\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "Entonces, el modelo está más seguro de que esta imagen es un \"???\". Podemos verificar la etiqueta de prueba (recuerde, esta es la verdadera identidad del dígito) para ver si esta predicción es correcta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "source": [
        "print(\"Label of this digit is:\", test_labels[0])\n",
        "plt.imshow(test_images[0,:,:,0], cmap=plt.cm.binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Visualicemos los resultados de la clasificación en el conjunto de datos MNIST. Trazaremos imágenes del conjunto de datos de prueba junto con su etiqueta predicha, así como un histograma que proporciona las probabilidades de predicción para cada uno de los dígitos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "source": [
        "#@title Change the slider to look at the model's predictions! { run: \"auto\" }\n",
        "\n",
        "image_index = 24 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "plt.subplot(1,2,1)\n",
        "mdl.lab2.plot_image_prediction(image_index, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "mdl.lab2.plot_value_prediction(image_index, predictions,  test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "También podemos trazar varias imágenes junto con sus predicciones, donde las etiquetas de predicción correctas son azules y las etiquetas de predicción incorrectas son grises. El número proporciona el porcentaje de confianza (sobre 100) para la etiqueta predicha. ¡Tenga en cuenta que el modelo puede tener mucha confianza en una predicción incorrecta!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "source": [
        "# Plots the first X test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "num_rows = 5\n",
        "num_cols = 9\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  mdl.lab2.plot_image_prediction(i, predictions, test_labels, test_images)\n",
        "  #plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  #mdl.lab2.plot_value_prediction(i, predictions, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-2glsRiMdqa"
      },
      "source": [
        "## 1.4 Entrenando el modelo 2.0\n",
        "\n",
        "Anteriormente, usamos la llamada a la función [`fit`](https://www.tensorflow.org/api_docs/python/tf/keras/models/Sequential#fit) para entrenar el modelo. Esta función es bastante intuitiva y de alto nivel, lo que es realmente útil para modelos más simples. Como puede ver, esta función abstrae muchos detalles en la llamada de entrenamiento y tenemos menos control sobre el modelo de entrenamiento, lo que podría ser útil en otros contextos.\n",
        "\n",
        "Como alternativa a esto, podemos usar la clase [`tf.GradientTape`](https://www.tensorflow.org/api_docs/python/tf/GradientTape) para registrar las operaciones de diferenciación durante el entrenamiento, y luego llamar a la [` tf.GradientTape.gradient`](https://www.tensorflow.org/api_docs/python/tf/GradientTape#gradient) para calcular los gradientes.\n",
        "\n",
        "Usaremos este marco para entrenar nuestro `cnn_model` usando el descenso de gradiente estocástico."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wq34id-iN1Ml"
      },
      "source": [
        "# Rebuild the CNN model\n",
        "cnn_model = build_cnn_model()\n",
        "\n",
        "batch_size = 12\n",
        "loss_history = mdl.util.LossHistory(smoothing_factor=0.95) # to record the evolution of the loss\n",
        "plotter = mdl.util.PeriodicPlotter(sec=2, xlabel='Iterations', ylabel='Loss', scale='semilogy')\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2) # define our optimizer\n",
        "\n",
        "if hasattr(tqdm, '_instances'): tqdm._instances.clear() # clear if it exists\n",
        "\n",
        "for idx in tqdm(range(0, train_images.shape[0], batch_size)):\n",
        "  # First grab a batch of training data and convert the input images to tensors\n",
        "  (images, labels) = (train_images[idx:idx+batch_size], train_labels[idx:idx+batch_size])\n",
        "  images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "\n",
        "  # GradientTape to record differentiation operations\n",
        "  with tf.GradientTape() as tape:\n",
        "    #'''TODO: feed the images into the model and obtain the predictions'''\n",
        "    logits = cnn_model(images)\n",
        "    # logits = # TODO\n",
        "\n",
        "    #'''TODO: compute the categorical cross entropy loss\n",
        "    loss_value = tf.keras.backend.sparse_categorical_crossentropy(labels, logits)\n",
        "    # loss_value = tf.keras.backend.sparse_categorical_crossentropy() # TODO\n",
        "\n",
        "  loss_history.append(loss_value.numpy().mean()) # append the loss to the loss_history record\n",
        "  plotter.plot(loss_history.get())\n",
        "\n",
        "  # Backpropagation\n",
        "  '''TODO: Use the tape to compute the gradient against all parameters in the CNN model.\n",
        "      Use cnn_model.trainable_variables to access these parameters.'''\n",
        "  grads = tape.gradient(loss_value, cnn_model.trainable_variables)\n",
        "  # grads = # TODO\n",
        "  optimizer.apply_gradients(zip(grads, cnn_model.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cNtDhVaqEdR"
      },
      "source": [
        "## 1.5 Conclusión\n",
        "En esta parte del laboratorio, tuvo la oportunidad de jugar con diferentes clasificadores MNIST con diferentes arquitecturas (solo capas completamente conectadas, CNN) y experimentar cómo los diferentes hiperparámetros afectan la precisión (tasa de aprendizaje, etc.). La siguiente parte del laboratorio explora otra aplicación de las CNN, la detección facial y algunos inconvenientes de los sistemas de inteligencia artificial en aplicaciones del mundo real, como cuestiones de sesgo."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Transfeer Learning"
      ],
      "metadata": {
        "id": "IbE_xwDIb5W1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necesarias\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "# Cargar el modelo preentrenado VGG16\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Congelar todas las capas del modelo base\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Añadir capas personalizadas\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)  # Asumiendo 10 clases para la clasificación de prendas\n",
        "\n",
        "# Crear el modelo final\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo (utilice su propio conjunto de datos)\n",
        "# model.fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(val_data, val_labels))\n",
        "\n",
        "# Descongelar algunas de las últimas capas y realizar un segundo entrenamiento\n",
        "for layer in base_model.layers[-4:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Volver a compilar el modelo y entrenar\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# model.fit(train_data, train_labels, epochs=5, batch_size=32, validation_data=(val_data, val_labels))\n",
        "\n",
        "# Evaluar el modelo (utilice su propio conjunto de datos de prueba)\n",
        "# test_loss, test_acc = model.evaluate(test_data, test_labels)\n"
      ],
      "metadata": {
        "id": "C18ZVHE_ekR0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}